# ================= INSTALL =================
!pip install -q torch torchvision pandas scikit-learn pillow requests

# ================= IMPORTS =================
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import resnet18
from PIL import Image
import pandas as pd
import numpy as np
import requests
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from torch.utils.data import Dataset, DataLoader
import os

# ================= CREATE SAMPLE DATASET =================
os.makedirs("dataset/images", exist_ok=True)

# Download sample house images
image_urls = [
    "https://images.unsplash.com/photo-1568605114967-8130f3a36994",
    "https://images.unsplash.com/photo-1570129477492-45c003edd2be",
    "https://images.unsplash.com/photo-1600585154340-be6161a56a0c",
    "https://images.unsplash.com/photo-1605276374104-dee2a0ed3cd6",
    "https://images.unsplash.com/photo-1600607687939-ce8a6c25118c",
    "https://images.unsplash.com/photo-1599423300746-b62533397364",
    "https://images.unsplash.com/photo-1580587771525-78b9dba3b914",
    "https://images.unsplash.com/photo-1600047509782-20d39509f26d"
]

data = []

for i, url in enumerate(image_urls):
    img_data = requests.get(url).content
    img_name = f"house{i}.jpg"
    
    with open(f"dataset/images/{img_name}", "wb") as f:
        f.write(img_data)

    # Create synthetic tabular data
    bedrooms = np.random.randint(2,6)
    bathrooms = np.random.randint(1,4)
    area = np.random.randint(800,3500)
    
    price = bedrooms*50000 + bathrooms*30000 + area*120 + np.random.randint(-20000,20000)

    data.append([img_name, bedrooms, bathrooms, area, price])

df = pd.DataFrame(data, columns=["image","bedrooms","bathrooms","area","price"])
df.to_csv("dataset/data.csv", index=False)

print("Dataset created!")

# ================= LOAD DATA =================
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# ================= DATASET CLASS =================
class HousingDataset(Dataset):
    def __init__(self, dataframe, img_dir, transform=None):
        self.df = dataframe
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_name = os.path.join(self.img_dir, self.df.iloc[idx]["image"])
        image = Image.open(img_name).convert("RGB")

        if self.transform:
            image = self.transform(image)

        tabular = torch.tensor(
            self.df.iloc[idx][["bedrooms","bathrooms","area"]].values.astype(float),
            dtype=torch.float32
        )

        price = torch.tensor(self.df.iloc[idx]["price"], dtype=torch.float32)

        return image, tabular, price

# ================= TRANSFORMS =================
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

train_dataset = HousingDataset(train_df, "dataset/images", transform)
test_dataset = HousingDataset(test_df, "dataset/images", transform)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4)

# ================= MODEL =================
class MultiModalModel(nn.Module):
    def __init__(self, tabular_size):
        super().__init__()

        self.cnn = resnet18(pretrained=True)
        self.cnn.fc = nn.Linear(512, 128)

        self.tabular_net = nn.Sequential(
            nn.Linear(tabular_size, 64),
            nn.ReLU(),
            nn.Linear(64, 32)
        )

        self.combined = nn.Sequential(
            nn.Linear(160, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(self, image, tabular):
        img_feat = self.cnn(image)
        tab_feat = self.tabular_net(tabular)
        combined = torch.cat((img_feat, tab_feat), dim=1)
        return self.combined(combined)

# ================= TRAIN =================
device = "cuda" if torch.cuda.is_available() else "cpu"
model = MultiModalModel(tabular_size=3).to(device)

criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

epochs = 3

for epoch in range(epochs):
    model.train()
    for images, tabular, prices in train_loader:
        images, tabular, prices = images.to(device), tabular.to(device), prices.to(device)

        preds = model(images, tabular).squeeze()
        loss = criterion(preds, prices)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch+1}, Loss: {loss.item():.2f}")

# ================= EVALUATION =================
model.eval()
preds_list = []
true_list = []

with torch.no_grad():
    for images, tabular, prices in test_loader:
        images, tabular = images.to(device), tabular.to(device)

        preds = model(images, tabular).squeeze().cpu().numpy()

        preds_list.extend(preds)
        true_list.extend(prices.numpy())

mae = mean_absolute_error(true_list, preds_list)
rmse = np.sqrt(mean_squared_error(true_list, preds_list))

print("MAE:", mae)
print("RMSE:", rmse)
  The output is 
 Dataset created!
/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
100%|██████████| 44.7M/44.7M [00:00<00:00, 94.7MB/s]
Epoch 1, Loss: 349467967488.00
Epoch 2, Loss: 307985350656.00
Epoch 3, Loss: 173742669824.00
MAE: 453881.0856933594
RMSE: 459384.6961464678
